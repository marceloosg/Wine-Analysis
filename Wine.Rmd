---
title: "Wine analysis"
output:
  html_document:
    df_print: paged
---

#Objetive:

##Create a model to estimate the wine quality.

##Original Problem Description:

1. The problem:
  * The present problem refers to the data of portuguese wines "Vinho Verde" (Green Wine), which 
have white and red variants. Due to privacy issues, only the physical-chemical  (input) 
and sensory (output) variables are available ( for instance, there is no data about which kind of grape,
brand of wine, price of sale, etc).
2. Sources
   * Created by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009
3. Past Usage:
  * P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
  * Modeling wine preferences by data mining from physicochemical properties.
  * In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.
  * In the above reference, two datasets were created, using red and white wine samples.
  * The inputs include objective tests (e.g. PH values) and the output is based on sensory data
  (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality 
  between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model
  these datasets under a regression approach. The support vector machine model achieved the
  best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T),
  etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity
  analysis procedure).
4. Relevant Information:
   * The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine.
   * For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009](https://www.sciencedirect.com/science/article/pii/S0167923609001377?via%3Dihub).
   * Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables 
   are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).
   * These datasets can be viewed as classification or regression tasks.
   * The classes are ordered and not balanced (e.g. there are munch more normal wines than
   excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent
   or poor wines. Also, we are not sure if all input variables are relevant. So
   it could be interesting to test feature selection methods. 
5. Number of Instances: red wine - 1599; white wine - 4898. 
6. Number of Attributes: 11 + output attribute
   * Note: several of the attributes may be correlated, thus it makes sense to apply some sort of
   feature selection.
   * For more information, read [Cortez et al., 2009](https://www.sciencedirect.com/science/article/pii/S0167923609001377?via%3Dihub).

*Input* variables (based on physicochemical tests):

7. Attribute information:
  * fixed acidity
  * volatile acidity
  * citric acid
  * residual sugar
  * chlorides
  * free sulfur dioxide
  * total sulfur dioxide
  * density
  * pH
  * sulphates
  * alcohol
  
*Output* variable (based on sensory data): 

  * Quality (score between 0 and 10)

8. Missing Attribute Values: None

##Quick literature review

First step taken is to do a quick bibliography review about the subject in order to reproduce previously conducted research and
improve upon it.

##Google Search

###First Review
at "30/11/2018 21:00 GMT -3, daylight saving" :

   * All input variables were added to the search, which returned one match to this [link](https://pubag.nal.usda.gov/pubag/downloadPDF.xhtml?id=27220&content=PDF). This paper provides a description of the effect of physical-chemical properties of tomatoes on its flavour.
   
   * The words 'wine quality analysis portuguese "Vinho Verde"' were pre-appended to the 
  previously search and the first hit provided this [link](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwjPgoCVnP3eAhXJk5AKHf9cDbwQFjAAegQIBBAB&url=https%3A%2F%2Farchive.ics.uci.edu%2Fml%2Fdatasets%2FWine%252BQuality&usg=AOvVaw1Q_6pY55safkphipOhAHF1)
  which lead to the reference at this [link](https://www.sciencedirect.com/science/article/pii/S0167923609001377?via%3Dihub) and
  the original dataset [here](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/). 
  
  * The above paper was not publicly available. A search for the name of the paper (*Modeling wine preferences by data mining from physicochemical properties*) resulted on a similar public paper at this [link](http://www.scitepress.org/Papers/2015/55519/55519.pdf). 
  
  * This paper titled 'Modeling Wine Preferences from Physicochemical Properties using Fuzzy techniques' contains a comparison of several models of the same dataset and therefore were selected for a detailed analysis the review.
  
  * Other results for "Modeling wine preferences by data mining fromphysicochemical  properties.  In  Decision  SupportSystems arxiv" were saved for a second take on bibliography review.


##Download exercice Data:

```{r, cache=T}
library(data.table)

url='https://drive.google.com/uc?auth_user=0&id=1-oG5-kBt9xQ3Li4PEexpiA9_7RZhRM1f&export=download'
temp <- tempfile(fileext = ".csv")
download.file(url,temp)
wine <- fread(temp, sep = ";", encoding = 'UTF-8')
print(wine[,lapply(.SD,class),type])
```

It is strange that the alcohol is classified as character.

```{r , cache=T}
names(table(wine[type=="White"]$alcohol)[1:20])
```

## The data seems to be corrupted. The original dataset looks like: 

```{r,cache=T}
library(data.table)
url='https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
#temp <- tempfile(fileext = ".csv")
temp='data/winequality-white.csv'
if(!file.exists(temp)){
  download.file(url, temp)
}
wine_or <- fread(temp, sep = ";", encoding = 'UTF-8')
url='https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
temp='data/winequality-red.csv'
if(!file.exists(temp)){
  download.file(url, temp)
}
wine_red <- fread(temp, sep = ";", encoding = 'UTF-8')
wine_or$type="White"
wine_red$type="Red"
wine=rbind(wine_or,wine_red)
print(wine_or[,lapply(.SD,class),])

```


## Comparison
```{r}
hist(wine_or$alcohol)
names(table(wine_or$alcohol)[1:20])
```


The alcohol levels must be between 8 and 15:
```{r, cache=T}
a=as.numeric(gsub("\\.","",wine$alcohol))
a=a/10^floor(log(a)/log(10))
a[a<5]=a[a<5]*10
wine$alcohol=a
sum(wine[type=="White"]$alcohol-wine_or$alcohol)
```

The assumption was correct, after ajusting the data the difference is really small, we should use the original data to avoid
these errors.


Let's see if the data from the paper matches the one at hand. Let's compare both summary data:

Paper's:

![Fuzzy](https://github.com/marceloosg/Wine-Analysis/raw/master/pictures/summary.png)

```{r,cache=T}
(t(wine[,lapply(.SD,function(s){list(min(s),max(s),mean(s))}),type]))
```

Before trying to reproduce a complex model like FIR. Let's see the properties of our input data to see if there is a simpler
model we can try first.


### Are our input data Normal?

Applying the jarque.bera.test(x) to all input variables. If the p.value is below 0.05/12, we reject the null normality hypothesis.

```{r,cache=T}
library(tseries)
vars=wine[,lapply(.SD, function(s) jarque.bera.test(s)[3]),.SDcols = setdiff(colnames(wine),c("Quality","type")), type]
mvars=melt(vars,id.vars='type')
mvars$value=unlist(mvars$value)
mvars=mvars[,.(pvalue=sum(value)),type]
mvars
```

It is a strong case for normality, let's perform a visual inspection on centered and scaled variables
```{r,cache=T}
library(ggplot2)
mwine=melt(wine,id.vars='type')
mwine[,value:=scale(value),.(type,variable)]
ggplot(mwine,aes(x=value,fill=type,alpha=ifelse(type=="White",0.5,0.6)))+geom_density()+facet_wrap(~variable)
```
They are somewhat normal, but a closer Inspection may be due for the residual sugar and citric acid.

## Bivariate analysis

### What is the correlation between the variables? 
```{r,cache=T}
library(GGally)
m=cbind(wine[type=="White",1:11],scale(wine[type=="White"]$quality))
names(m)[12]="quality"
dm=cor(m)
ggcorr(m,label=T)
```

## How can we group similar inputs?
```{r,cache=T}
plot(hclust(dist(dm)))
```



### Remove colinearity with principal components analysis
```{r,cache=T}
r=prcomp(wine[type=="White",1:11],scale=T)
((r$sdev^2/sum(r$sdev^2))) 
```

# define importance by the order of the correlation of the components with the target variable
```{r,cache=T}
components=predict(r,newdata=wine[type=="White",1:11])
correlation=cor(components,wine[type=="White", "quality"])
importance=as.data.table(correlation,keep.rownames = T)[order(-abs(quality))]
importance
```
# A quick analysis of variance let us discard components not significant to the regression
```{r,cache=T}
pcdata=data.table(components[,importance$rn])
pcdata$group = as.double(wine[type=="White"]$quality)
summary(aov(group ~ .,data=pcdata))
```

A cross validated regression would soften the impact of outliers in the dataset
```{r,cache=T}
source("fit.R")
results=myfit(pcdata[,-c("PC7","PC6")], 'lm')
(results$train)
```

The results are compatible with the Multiple Regression present at [Modeling Wine Preferences from Physicochemical Properties using Fuzzy inductive reasoning](http://www.scitepress.org/Papers/2015/55519/55519.pdf).

## How different are the means of each input compared to the quality?
```{r,cache=T}
q=mwine[variable=="quality"]$value
qmwine=mwine[variable!="quality"]
qmwine$quality=q
qmwine=qmwine[,.(mean=mean(value), sm =sd(value),N=.N),.(variable,type,quality)]
ggplot(qmwine[order(quality,type,variable)],aes(x=mean,y=quality,color=type,size=N,weight=N/sm))+
  geom_smooth(method="lm",se=T)+geom_point()+facet_grid(variable~type)
```

#Leverage
The top two grades also deviates, but differently
```{r,warning=F, cache=T}
qmwine$group = "Standard"
qmwine[quality< -2]$group = "Low"
qmwine[quality > 2.5]$group = "High"

ggplot(qmwine[order(quality,type,variable)],aes(x=mean,y=quality,size=N,weight=N/sm))+
  geom_smooth(data=qmwine[group=="Standard"],method="lm",se=T,aes(linetype=type,group=group))+geom_point(aes(color=group),alpha=0.5)+facet_grid(variable~type)
```

The lower quality wine (lowest fourth grades) seems to deviate from the linear tendencies. Let's highlight those differences.
```

ggplot(qmwine[order(quality,type,variable)][quality>-2],aes(x=mean,y=quality,size=N,weight=N/sm))+
  geom_smooth(method="lm",se=T,aes(color=type))+geom_point(aes(color=factor(quality)),alpha=0.5)+facet_grid(variable~type)
```


### LDA classification and regression
```{r,warning=F, cache=T}
#training=pcdata
quality=c("Lowest", "Low", "MediumLow","Medium","MediumHigh","High" ,"Highest")
#training$group = factor(quality[training$quality-2], levels=quality, ordered=T)
#training=training[,-c("quality","type")]
#regdata=pcdata
#regdata$group=as.character(regdata)
#set.seed(814) # to have reproducible results
source("fit.R")
classdata=pcdata[,-c("PC7","PC6")]
classdata$group=factor(quality[classdata$group-2]
                       , levels=quality, ordered=T)
ldafit=myfit(classdata,'lda')
#predicted=data.table(predict(ldafit$train,newdata = ldafit$testdata,type="prob"))

mad=sum(ldafit$test==ldafit$testdata$group)/dim(ldafit$testdata)[1]
print(mad)
table(ldafit$test,ldafit$testdata$group)/dim(ldafit$testdata)[1]
```

# Next steps

* To reproduce and improve the FIR algorithm applied at ["Modeling Wine Preferences from Physicochemical Properties using Fuzzy inductive reasoning" ](http://www.scitepress.org/Papers/2015/55519/55519.pdf)

## Hypothesis to be tested:

  1. The discretization process is a crutial part of the FIR algorithm.
  2. Maybe we could use Linear Discriminant Analysis to find the separation points for each input variable. 
  3. The dimensionality should not be a problem if we use PCA before LDA.